# Ensemble Methods

Goal: join models together to get a better model

- Bagging: bootstrap aggregating
  - get individual model predicitons
  - combine them together

- Boosting
  - similar but tries harder to exploit each model's strength
  - one model (strong learners) might answer well in some part of the data but not well in other parts(weak learner) while the other model might be more powerful in another part. It's not necessary to have all model as strong learners, each of them is just need to be slightly better than random guess


## Why Ensemble

- Bias vs. Variance

